{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1728918869931,
     "user": {
      "displayName": "Darshan Gohil",
      "userId": "05613917696562617294"
     },
     "user_tz": -330
    },
    "id": "N-M-vPEtcVsP"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Image Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1728918869932,
     "user": {
      "displayName": "Darshan Gohil",
      "userId": "05613917696562617294"
     },
     "user_tz": -330
    },
    "id": "k6XRISqHkLZ6",
    "outputId": "5ac1caa8-73b9-4b77-faf2-51adf3829ca1"
   },
   "outputs": [],
   "source": [
    "# Initialize the camera (0 is the default camera, change the index if you have multiple cameras)\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera is opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open the camera.\")\n",
    "else:\n",
    "    print(\"Camera opened successfully!\")\n",
    "\n",
    "# Capture an image from the camera\n",
    "ret, frame = camera.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1728918869932,
     "user": {
      "displayName": "Darshan Gohil",
      "userId": "05613917696562617294"
     },
     "user_tz": -330
    },
    "id": "yW2ANiAXk1nc",
    "outputId": "b0ccb157-9c34-4f10-bb1a-95cd521507c7"
   },
   "outputs": [],
   "source": [
    "# Capture an image from the camera\n",
    "ret, frame = camera.read()\n",
    "\n",
    "# Check if the image was captured successfully\n",
    "if ret:\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Step 1: Normalization\n",
    "    # Normalize the brightness and contrast of the image\n",
    "    normalized_image = cv2.normalize(\n",
    "        frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Step 2: Filtering\n",
    "    # Convert to grayscale to simplify filtering operations\n",
    "    gray_image = cv2.cvtColor(normalized_image, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    filtered_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Step 3: Segmentation using Thresholding\n",
    "    # Use adaptive thresholding to segment the product from the background\n",
    "    segmented_image = cv2.adaptiveThreshold(\n",
    "        filtered_image,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        11,\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    # save images\n",
    "    cv2.imwrite(\"captured_image.jpg\", frame)\n",
    "    cv2.imwrite(\"normalized_image.jpg\", normalized_image)\n",
    "    cv2.imwrite(\"filtered_image.jpg\", filtered_image)\n",
    "    cv2.imwrite(\"segmented_image.jpg\", segmented_image)\n",
    "\n",
    "    # Display the results of each preprocessing step\n",
    "    cv2.imshow(\"Original Image\", frame)\n",
    "    cv2.imshow(\"Normalized Image\", normalized_image)\n",
    "    cv2.imshow(\"Filtered Image\", filtered_image)\n",
    "    cv2.imshow(\"Segmented Image\", segmented_image)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Could not capture an image.\")\n",
    "\n",
    "# Release the camera resources\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "executionInfo": {
     "elapsed": 2431,
     "status": "ok",
     "timestamp": 1728918872351,
     "user": {
      "displayName": "Darshan Gohil",
      "userId": "05613917696562617294"
     },
     "user_tz": -330
    },
    "id": "G0VnNxKOcnbP",
    "outputId": "fef33420-b770-4c2b-a10b-d77bf6c29f05",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image_path = \"/captured_image.jpg\"\n",
    "# image_path = \"/content/drive/MyDrive/image2.webp\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide the axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract Text from the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6164,
     "status": "ok",
     "timestamp": 1728918878499,
     "user": {
      "displayName": "Darshan Gohil",
      "userId": "05613917696562617294"
     },
     "user_tz": -330
    },
    "id": "_6lvyXuOGOUM",
    "outputId": "dd07a11f-246b-4017-b537-5a5566cc6fde",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "# Convert the image to OpenCV format\n",
    "image_cv = np.array(image)\n",
    "image_cv = cv2.cvtColor(image_cv, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Convert the image to grayscale for better OCR results\n",
    "gray_image = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply adaptive thresholding to enhance text visibility\n",
    "thresh_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                     cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Use Tesseract OCR to extract text from the image\n",
    "extracted_text = pytesseract.image_to_string(thresh_image)\n",
    "print(\"Extracted Text from the Image:\")\n",
    "print(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1728918878499,
     "user": {
      "displayName": "Darshan Gohil",
      "userId": "05613917696562617294"
     },
     "user_tz": -330
    },
    "id": "N6ct-7a5bvhP",
    "outputId": "96021447-1650-43ef-bf13-29b1cadcbb1e"
   },
   "outputs": [],
   "source": [
    "# Detect edges using the Canny edge detector\n",
    "edges = cv2.Canny(gray_image, 50, 150)\n",
    "\n",
    "# Find contours based on the detected edges\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw the detected contours on the original image\n",
    "contour_image = image_cv.copy()\n",
    "cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with detected contours\n",
    "plt.imshow(cv2.cvtColor(contour_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')  # Hide the axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Deep Learning & Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2080,
     "status": "ok",
     "timestamp": 1728918880567,
     "user": {
      "displayName": "Darshan Gohil",
      "userId": "05613917696562617294"
     },
     "user_tz": -330
    },
    "id": "r70ThSDvb2pu",
    "outputId": "40fb9b72-033c-42e7-e1eb-dee60acd3c05"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Preprocess the image for MobileNetV2\n",
    "image_resized = image.resize((224, 224))  # Resize to the input size of the model\n",
    "image_array = np.array(image_resized) / 255.0  # Normalize pixel values\n",
    "input_image = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Load the pre-trained MobileNetV2 model\n",
    "model = tf.keras.applications.MobileNetV2(weights='imagenet')\n",
    "\n",
    "# Perform object detection\n",
    "predictions = model.predict(input_image)\n",
    "\n",
    "# Decode the predictions to get the top 3 predictions\n",
    "decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0]\n",
    "print(\"Top Predictions for the Image:\")\n",
    "for i, (imagenet_id, label, confidence) in enumerate(decoded_predictions):\n",
    "    print(f\"{i + 1}: {label} ({confidence * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1728918881613,
     "user": {
      "displayName": "Darshan Gohil",
      "userId": "05613917696562617294"
     },
     "user_tz": -330
    },
    "id": "6r7nqroHcQdH"
   },
   "outputs": [],
   "source": [
    "# Example: Fine-tune the pre-trained model for your product data (optional)\n",
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze the layers of the base model\n",
    "\n",
    "# Add a custom classification layer on top of the base model\n",
    "custom_model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(product_database), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the custom model\n",
    "custom_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Note: To train this model, you would need a labeled dataset of images for your specific products\n",
    "# custom_model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1728918881613,
     "user": {
      "displayName": "Darshan Gohil",
      "userId": "05613917696562617294"
     },
     "user_tz": -330
    },
    "id": "uJceFiIpco25"
   },
   "outputs": [],
   "source": [
    "# Mock product database with relevant details for each product\n",
    "product_database = {\n",
    "    'Packet': {'name': 'packet', 'price': '$2.99', 'specifications': 'Bar soap for cleaning', 'serial': '12345'},\n",
    "    'Shampoo': {'name': 'Shampoo', 'price': '$5.49', 'specifications': 'Haircare product in a bottle', 'serial': '67890'},\n",
    "    'Toothpaste': {'name': 'Toothpaste', 'price': '$3.25', 'specifications': 'Fluoride toothpaste in a tube', 'serial': '24680'}\n",
    "}\n",
    "\n",
    "# Function to display product details after identification\n",
    "def display_product_details(product_name, product_details):\n",
    "    if product_details:\n",
    "        print(f\"Product Identified: {product_name}\")\n",
    "        print(f\"Price: {product_details['price']}\")\n",
    "        print(f\"Specifications: {product_details['specifications']}\")\n",
    "    else:\n",
    "        print(\"Product not found in the database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1728918881613,
     "user": {
      "displayName": "Darshan Gohil",
      "userId": "05613917696562617294"
     },
     "user_tz": -330
    },
    "id": "4uhfQFnZc0A7"
   },
   "outputs": [],
   "source": [
    "# Check if the identified product is correct or if it needs to be rejected\n",
    "def real_time_feedback(product_name, product_details):\n",
    "    if product_name == \"Unknown Product\" or not product_details:\n",
    "        print(\"Defective or incorrect product detected\")\n",
    "        # Code to trigger an alert or automated response (e.g., reject product)\n",
    "    else:\n",
    "        print(\"Product is correctly identified and accepted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1728918881613,
     "user": {
      "displayName": "Darshan Gohil",
      "userId": "05613917696562617294"
     },
     "user_tz": -330
    },
    "id": "07ZN7hG6c7kT",
    "outputId": "ccbf6340-1fd3-4d2a-e9a6-b6c5602591d4"
   },
   "outputs": [],
   "source": [
    "# Example usage of all the functions\n",
    "product_match, product_details = match_product_with_database(predicted_label)\n",
    "display_product_details(product_match, product_details)\n",
    "real_time_feedback(product_match, product_details)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPpMeUZVIfQ17mDB8ptXrKG",
   "gpuType": "T4",
   "mount_file_id": "1mNVv6b_xN-MjiNXvwUXI6077WmYK1syl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
